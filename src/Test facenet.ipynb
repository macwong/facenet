{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recognition with Tensorflow and FaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/davidsandberg/facenet/wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import facenet\n",
    "import lfw\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import brentq\n",
    "from scipy import interpolate\n",
    "\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and classifying code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-e3b040728752>:31: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(cls.image_paths)>0, 'There must be at least one image for each class in the dataset')\n"
     ]
    }
   ],
   "source": [
    "def classifier(mode, # = 'CLASSIFY', \n",
    "               data_dir, # = '../data/subset/train', \n",
    "               classifier_filename, # = '../data/subset/subset_classifier.pkl', \n",
    "               model = '../data/models/20170512-110547.pb', \n",
    "               use_split_dataset = False, \n",
    "               test_data_dir = '../data/subset/test', \n",
    "               batch_size=90, \n",
    "               image_size=160, \n",
    "               seed=666, \n",
    "               min_nrof_images_per_class=20, \n",
    "               nrof_train_images_per_class=10):\n",
    "  \n",
    "    with tf.Graph().as_default():\n",
    "      \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            np.random.seed(seed=seed)\n",
    "            \n",
    "            if use_split_dataset:\n",
    "                dataset_tmp = facenet.get_dataset(data_dir)\n",
    "                train_set, test_set = split_dataset(dataset_tmp, min_nrof_images_per_class, nrof_train_images_per_class)\n",
    "                if (mode=='TRAIN'):\n",
    "                    dataset = train_set\n",
    "                elif (mode=='CLASSIFY'):\n",
    "                    dataset = test_set\n",
    "            else:\n",
    "                dataset = facenet.get_dataset(data_dir)\n",
    "\n",
    "            # Check that there are at least one training image per class\n",
    "            for cls in dataset:\n",
    "                assert(len(cls.image_paths)>0, 'There must be at least one image for each class in the dataset')            \n",
    "\n",
    "                 \n",
    "            paths, labels = facenet.get_image_paths_and_labels(dataset)\n",
    "            \n",
    "            print('Number of classes: %d' % len(dataset))\n",
    "            print('Number of images: %d' % len(paths))\n",
    "            \n",
    "            # Load the model\n",
    "            print('Loading feature extraction model')\n",
    "            facenet.load_model(model)\n",
    "            \n",
    "            # Get input and output tensors\n",
    "            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "            embedding_size = embeddings.get_shape()[1]\n",
    "            \n",
    "            # Run forward pass to calculate embeddings\n",
    "            print('Calculating features for images')\n",
    "            nrof_images = len(paths)\n",
    "            nrof_batches_per_epoch = int(math.ceil(1.0*nrof_images / batch_size))\n",
    "            emb_array = np.zeros((nrof_images, embedding_size))\n",
    "            for i in range(nrof_batches_per_epoch):\n",
    "                start_index = i*batch_size\n",
    "                end_index = min((i+1)*batch_size, nrof_images)\n",
    "                paths_batch = paths[start_index:end_index]\n",
    "                images = facenet.load_data(paths_batch, False, False, image_size)\n",
    "                feed_dict = { images_placeholder:images, phase_train_placeholder:False }\n",
    "                emb_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "            \n",
    "            classifier_filename_exp = os.path.expanduser(classifier_filename)\n",
    "\n",
    "            if (mode=='TRAIN'):\n",
    "                # Train classifier\n",
    "                print('Training classifier')\n",
    "                model = SVC(kernel='linear', probability=True)\n",
    "                model.fit(emb_array, labels)\n",
    "            \n",
    "                # Create a list of class names\n",
    "                class_names = [ cls.name.replace('_', ' ') for cls in dataset]\n",
    "\n",
    "                # Saving classifier model\n",
    "                with open(classifier_filename_exp, 'wb') as outfile:\n",
    "                    pickle.dump((model, class_names), outfile)\n",
    "                print('Saved classifier model to file \"%s\"' % classifier_filename_exp)\n",
    "                \n",
    "            elif (mode=='CLASSIFY'):\n",
    "                # Classify images\n",
    "                print('Testing classifier')\n",
    "                with open(classifier_filename_exp, 'rb') as infile:\n",
    "                    (model, class_names) = pickle.load(infile)\n",
    "\n",
    "                print('Loaded classifier model from file \"%s\"' % classifier_filename_exp)\n",
    "\n",
    "                predictions = model.predict_proba(emb_array)\n",
    "                best_class_indices = np.argmax(predictions, axis=1)\n",
    "                best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n",
    "                \n",
    "                for i in range(len(best_class_indices)):\n",
    "                    msg = \"WRONG!!!\"\n",
    "                    \n",
    "                    if np.equal(best_class_indices[i], labels[i]):\n",
    "                        msg = \"Correct\"\n",
    "                        \n",
    "                    print(\"\\nReading \" + os.path.basename(paths[i]) + \"... \" + msg)\n",
    "                    print('%4d  %s: %.3f' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\n",
    "\n",
    "                    \n",
    "                accuracy = np.mean(np.equal(best_class_indices, labels))\n",
    "                print('\\nAccuracy: %.3f' % accuracy)\n",
    "                \n",
    "            \n",
    "def split_dataset(dataset, min_nrof_images_per_class, nrof_train_images_per_class):\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    for cls in dataset:\n",
    "        paths = cls.image_paths\n",
    "        # Remove classes with less than min_nrof_images_per_class\n",
    "        if len(paths)>=min_nrof_images_per_class:\n",
    "            np.random.shuffle(paths)\n",
    "            train_set.append(facenet.ImageClass(cls.name, paths[:nrof_train_images_per_class]))\n",
    "            test_set.append(facenet.ImageClass(cls.name, paths[nrof_train_images_per_class:]))\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple test with 9 people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 9\n",
      "Number of images: 18\n",
      "Loading feature extraction model\n",
      "Model filename: ../data/models/20170512-110547.pb\n",
      "Calculating features for images\n",
      "Training classifier\n",
      "Saved classifier model to file \"../data/subset_small/subset_classifier.pkl\"\n"
     ]
    }
   ],
   "source": [
    "classifier(mode = \"TRAIN\", \n",
    "           data_dir = '../data/subset_small/train', \n",
    "           classifier_filename = '../data/subset_small/subset_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 9\n",
      "Number of images: 9\n",
      "Loading feature extraction model\n",
      "Model filename: ../data/models/20170512-110547.pb\n",
      "Calculating features for images\n",
      "Testing classifier\n",
      "Loaded classifier model from file \"../data/subset_small/subset_classifier.pkl\"\n",
      "\n",
      "Reading Al_Pacino_0003.png... Correct\n",
      "   0  Al Pacino: 0.215\n",
      "\n",
      "Reading Ben_Affleck_0007.png... Correct\n",
      "   1  Ben Affleck: 0.214\n",
      "\n",
      "Reading Britney_Spears_0014.png... Correct\n",
      "   2  Britney Spears: 0.221\n",
      "\n",
      "Reading Halle_Berry_0016.png... Correct\n",
      "   3  Halle Berry: 0.279\n",
      "\n",
      "Reading Harbhajan_Singh_0002.png... Correct\n",
      "   4  Harbhajan Singh: 0.329\n",
      "\n",
      "Reading Oprah_Winfrey_0004.png... Correct\n",
      "   5  Oprah Winfrey: 0.207\n",
      "\n",
      "Reading Will_Smith_0002.png... Correct\n",
      "   6  Will Smith: 0.247\n",
      "\n",
      "Reading Winona_Ryder_0024.png... Correct\n",
      "   7  Winona Ryder: 0.212\n",
      "\n",
      "Reading Yao_Ming_0008.png... Correct\n",
      "   8  Yao Ming: 0.276\n",
      "\n",
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "classifier(mode = 'CLASSIFY', \n",
    "           data_dir = '../data/subset_small/test', \n",
    "           classifier_filename = '../data/subset_small/subset_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigger test with 100 people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 100\n",
      "Number of images: 200\n",
      "Loading feature extraction model\n",
      "Model filename: ../data/models/20170512-110547.pb\n",
      "Calculating features for images\n",
      "Training classifier\n",
      "Saved classifier model to file \"../data/subset_small/subset_classifier.pkl\"\n"
     ]
    }
   ],
   "source": [
    "classifier(mode = \"TRAIN\", \n",
    "           data_dir = '../data/newdir_train2_test1/train', \n",
    "           classifier_filename = '../data/newdir_train2_test1/classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 100\n",
      "Number of images: 100\n",
      "Loading feature extraction model\n",
      "Model filename: ../data/models/20170512-110547.pb\n",
      "Calculating features for images\n",
      "Testing classifier\n",
      "Loaded classifier model from file \"../data/subset_small/subset_classifier.pkl\"\n",
      "\n",
      "Reading Aaron_Peirsol_0003.png... Correct\n",
      "   0  Aaron Peirsol: 0.040\n",
      "\n",
      "Reading Abdoulaye_Wade_0003.png... Correct\n",
      "   1  Abdoulaye Wade: 0.040\n",
      "\n",
      "Reading Abdullah_0003.png... Correct\n",
      "   2  Abdullah: 0.036\n",
      "\n",
      "Reading Abdullah_Gul_0003.png... Correct\n",
      "   3  Abdullah Gul: 0.029\n",
      "\n",
      "Reading Abdullah_al-Attiyah_0003.png... Correct\n",
      "   4  Abdullah al-Attiyah: 0.030\n",
      "\n",
      "Reading Abel_Pacheco_0003.png... Correct\n",
      "   5  Abel Pacheco: 0.024\n",
      "\n",
      "Reading Abid_Hamid_Mahmud_Al-Tikriti_0003.png... Correct\n",
      "   6  Abid Hamid Mahmud Al-Tikriti: 0.026\n",
      "\n",
      "Reading Adam_Sandler_0003.png... Correct\n",
      "   7  Adam Sandler: 0.023\n",
      "\n",
      "Reading Adel_Al-Jubeir_0003.png... Correct\n",
      "   8  Adel Al-Jubeir: 0.039\n",
      "\n",
      "Reading Adolfo_Aguilar_Zinser_0003.png... Correct\n",
      "   9  Adolfo Aguilar Zinser: 0.029\n",
      "\n",
      "Reading Adrien_Brody_0003.png... Correct\n",
      "  10  Adrien Brody: 0.035\n",
      "\n",
      "Reading Ahmed_Chalabi_0003.png... Correct\n",
      "  11  Ahmed Chalabi: 0.025\n",
      "\n",
      "Reading Ai_Sugiyama_0003.png... Correct\n",
      "  12  Ai Sugiyama: 0.028\n",
      "\n",
      "Reading Aicha_El_Ouafi_0003.png... Correct\n",
      "  13  Aicha El Ouafi: 0.028\n",
      "\n",
      "Reading Akbar_Hashemi_Rafsanjani_0003.png... Correct\n",
      "  14  Akbar Hashemi Rafsanjani: 0.022\n",
      "\n",
      "Reading Akhmed_Zakayev_0003.png... WRONG!!!\n",
      "  15  Alastair Campbell: 0.030\n",
      "\n",
      "Reading Al_Gore_0003.png... Correct\n",
      "  16  Al Gore: 0.032\n",
      "\n",
      "Reading Al_Pacino_0003.png... Correct\n",
      "  17  Al Pacino: 0.020\n",
      "\n",
      "Reading Al_Sharpton_0003.png... Correct\n",
      "  18  Al Sharpton: 0.040\n",
      "\n",
      "Reading Alan_Greenspan_0003.png... Correct\n",
      "  19  Alan Greenspan: 0.034\n",
      "\n",
      "Reading Alastair_Campbell_0003.png... Correct\n",
      "  20  Alastair Campbell: 0.030\n",
      "\n",
      "Reading Albert_Costa_0003.png... Correct\n",
      "  21  Albert Costa: 0.046\n",
      "\n",
      "Reading Alec_Baldwin_0003.png... Correct\n",
      "  22  Alec Baldwin: 0.025\n",
      "\n",
      "Reading Alejandro_Avila_0003.png... WRONG!!!\n",
      "  23  Abdullah Gul: 0.022\n",
      "\n",
      "Reading Alejandro_Toledo_0003.png... WRONG!!!\n",
      "  24  Arturo Gatti: 0.021\n",
      "\n",
      "Reading Aleksander_Kwasniewski_0003.png... Correct\n",
      "  25  Aleksander Kwasniewski: 0.028\n",
      "\n",
      "Reading Alex_Sink_0003.png... Correct\n",
      "  26  Alex Sink: 0.041\n",
      "\n",
      "Reading Alexander_Downer_0003.png... Correct\n",
      "  27  Alexander Downer: 0.019\n",
      "\n",
      "Reading Alexander_Losyukov_0003.png... Correct\n",
      "  28  Alexander Losyukov: 0.029\n",
      "\n",
      "Reading Alexandra_Stevenson_0003.png... Correct\n",
      "  29  Alexandra Stevenson: 0.052\n",
      "\n",
      "Reading Ali_Khamenei_0003.png... Correct\n",
      "  30  Ali Khamenei: 0.042\n",
      "\n",
      "Reading Ali_Naimi_0003.png... Correct\n",
      "  31  Ali Naimi: 0.028\n",
      "\n",
      "Reading Allyson_Felix_0003.png... Correct\n",
      "  32  Allyson Felix: 0.042\n",
      "\n",
      "Reading Alvaro_Noboa_0003.png... WRONG!!!\n",
      "  33  Arlen Specter: 0.022\n",
      "\n",
      "Reading Alvaro_Silva_Calderon_0003.png... Correct\n",
      "  34  Alvaro Silva Calderon: 0.030\n",
      "\n",
      "Reading Alvaro_Uribe_0003.png... Correct\n",
      "  35  Alvaro Uribe: 0.024\n",
      "\n",
      "Reading Amanda_Bynes_0003.png... Correct\n",
      "  36  Amanda Bynes: 0.047\n",
      "\n",
      "Reading Amelia_Vega_0003.png... Correct\n",
      "  37  Amelia Vega: 0.040\n",
      "\n",
      "Reading Amelie_Mauresmo_0003.png... Correct\n",
      "  38  Amelie Mauresmo: 0.032\n",
      "\n",
      "Reading Amer_al-Saadi_0003.png... Correct\n",
      "  39  Amer al-Saadi: 0.024\n",
      "\n",
      "Reading Ana_Guevara_0003.png... Correct\n",
      "  40  Ana Guevara: 0.030\n",
      "\n",
      "Reading Ana_Palacio_0003.png... WRONG!!!\n",
      "  41  Ann Veneman: 0.023\n",
      "\n",
      "Reading Anastasia_Myskina_0003.png... Correct\n",
      "  42  Anastasia Myskina: 0.028\n",
      "\n",
      "Reading Anders_Ebbeson_0003.png... Correct\n",
      "  43  Anders Ebbeson: 0.039\n",
      "\n",
      "Reading Anders_Fogh_Rasmussen_0003.png... Correct\n",
      "  44  Anders Fogh Rasmussen: 0.024\n",
      "\n",
      "Reading Andre_Agassi_0003.png... Correct\n",
      "  45  Andre Agassi: 0.035\n",
      "\n",
      "Reading Andrew_Weissmann_0003.png... Correct\n",
      "  46  Andrew Weissmann: 0.040\n",
      "\n",
      "Reading Andy_Roddick_0003.png... Correct\n",
      "  47  Andy Roddick: 0.040\n",
      "\n",
      "Reading Angela_Bassett_0003.png... WRONG!!!\n",
      "  48  Allyson Felix: 0.036\n",
      "\n",
      "Reading Angela_Merkel_0003.png... Correct\n",
      "  49  Angela Merkel: 0.024\n",
      "\n",
      "Reading Angelina_Jolie_0003.png... Correct\n",
      "  50  Angelina Jolie: 0.044\n",
      "\n",
      "Reading Angelo_Reyes_0003.png... Correct\n",
      "  51  Angelo Reyes: 0.027\n",
      "\n",
      "Reading Anibal_Ibarra_0003.png... Correct\n",
      "  52  Anibal Ibarra: 0.028\n",
      "\n",
      "Reading Ann_Veneman_0003.png... Correct\n",
      "  53  Ann Veneman: 0.030\n",
      "\n",
      "Reading Anna_Kournikova_0003.png... Correct\n",
      "  54  Anna Kournikova: 0.030\n",
      "\n",
      "Reading Anne_Krueger_0003.png... Correct\n",
      "  55  Anne Krueger: 0.025\n",
      "\n",
      "Reading Anne_McLellan_0003.png... Correct\n",
      "  56  Anne McLellan: 0.036\n",
      "\n",
      "Reading Annette_Lu_0003.png... Correct\n",
      "  57  Annette Lu: 0.036\n",
      "\n",
      "Reading Antonio_Banderas_0003.png... Correct\n",
      "  58  Antonio Banderas: 0.029\n",
      "\n",
      "Reading Antonio_Palocci_0003.png... Correct\n",
      "  59  Antonio Palocci: 0.051\n",
      "\n",
      "Reading Antonio_Trillanes_0003.png... Correct\n",
      "  60  Antonio Trillanes: 0.032\n",
      "\n",
      "Reading Antony_Leung_0003.png... Correct\n",
      "  61  Antony Leung: 0.028\n",
      "\n",
      "Reading Ari_Fleischer_0003.png... Correct\n",
      "  62  Ari Fleischer: 0.032\n",
      "\n",
      "Reading Arianna_Huffington_0003.png... Correct\n",
      "  63  Arianna Huffington: 0.035\n",
      "\n",
      "Reading Ariel_Sharon_0003.png... Correct\n",
      "  64  Ariel Sharon: 0.028\n",
      "\n",
      "Reading Arlen_Specter_0003.png... Correct\n",
      "  65  Arlen Specter: 0.020\n",
      "\n",
      "Reading Arminio_Fraga_0003.png... Correct\n",
      "  66  Arminio Fraga: 0.035\n",
      "\n",
      "Reading Arnold_Palmer_0003.png... Correct\n",
      "  67  Arnold Palmer: 0.030\n",
      "\n",
      "Reading Arnold_Schwarzenegger_0003.png... Correct\n",
      "  68  Arnold Schwarzenegger: 0.027\n",
      "\n",
      "Reading Arnoldo_Aleman_0003.png... WRONG!!!\n",
      "  69  Ali Naimi: 0.018\n",
      "\n",
      "Reading Art_Howe_0003.png... Correct\n",
      "  70  Art Howe: 0.040\n",
      "\n",
      "Reading Arturo_Gatti_0003.png... Correct\n",
      "  71  Arturo Gatti: 0.053\n",
      "\n",
      "Reading Ashanti_0003.png... Correct\n",
      "  72  Ashanti: 0.049\n",
      "\n",
      "Reading Ashton_Kutcher_0003.png... Correct\n",
      "  73  Ashton Kutcher: 0.036\n",
      "\n",
      "Reading Atal_Bihari_Vajpayee_0003.png... Correct\n",
      "  74  Atal Bihari Vajpayee: 0.027\n",
      "\n",
      "Reading Augustin_Calleri_0003.png... Correct\n",
      "  75  Augustin Calleri: 0.051\n",
      "\n",
      "Reading Azra_Akin_0003.png... Correct\n",
      "  76  Azra Akin: 0.040\n",
      "\n",
      "Reading Barbara_Walters_0003.png... Correct\n",
      "  77  Barbara Walters: 0.040\n",
      "\n",
      "Reading Barbra_Streisand_0003.png... Correct\n",
      "  78  Barbra Streisand: 0.023\n",
      "\n",
      "Reading Bashar_Assad_0003.png... Correct\n",
      "  79  Bashar Assad: 0.027\n",
      "\n",
      "Reading Ben_Affleck_0003.png... Correct\n",
      "  80  Ben Affleck: 0.030\n",
      "\n",
      "Reading Ben_Curtis_0003.png... WRONG!!!\n",
      "  81  Andy Roddick: 0.023\n",
      "\n",
      "Reading Ben_Howland_0003.png... Correct\n",
      "  82  Ben Howland: 0.035\n",
      "\n",
      "Reading Benazir_Bhutto_0003.png... Correct\n",
      "  83  Benazir Bhutto: 0.042\n",
      "\n",
      "Reading Benjamin_Netanyahu_0003.png... Correct\n",
      "  84  Benjamin Netanyahu: 0.030\n",
      "\n",
      "Reading Bernard_Landry_0003.png... WRONG!!!\n",
      "  85  Anders Ebbeson: 0.021\n",
      "\n",
      "Reading Bernard_Law_0003.png... Correct\n",
      "  86  Bernard Law: 0.031\n",
      "\n",
      "Reading Bertie_Ahern_0003.png... Correct\n",
      "  87  Bertie Ahern: 0.038\n",
      "\n",
      "Reading Bijan_Darvish_0003.png... Correct\n",
      "  88  Bijan Darvish: 0.038\n",
      "\n",
      "Reading Biljana_Plavsic_0003.png... Correct\n",
      "  89  Biljana Plavsic: 0.030\n",
      "\n",
      "Reading Bill_Callahan_0003.png... Correct\n",
      "  90  Bill Callahan: 0.024\n",
      "\n",
      "Reading Bill_Clinton_0003.png... Correct\n",
      "  91  Bill Clinton: 0.040\n",
      "\n",
      "Reading Bill_Frist_0003.png... Correct\n",
      "  92  Bill Frist: 0.029\n",
      "\n",
      "Reading Bill_Gates_0003.png... WRONG!!!\n",
      "  93  Al Gore: 0.026\n",
      "\n",
      "Reading Bill_Graham_0003.png... WRONG!!!\n",
      "  94  Bill Paxton: 0.022\n",
      "\n",
      "Reading Bill_McBride_0003.png... Correct\n",
      "  95  Bill McBride: 0.028\n",
      "\n",
      "Reading Bill_Paxton_0003.png... Correct\n",
      "  96  Bill Paxton: 0.024\n",
      "\n",
      "Reading Bill_Simon_0003.png... Correct\n",
      "  97  Bill Simon: 0.026\n",
      "\n",
      "Reading Billy_Crystal_0003.png... Correct\n",
      "  98  Billy Crystal: 0.030\n",
      "\n",
      "Reading Binyamin_Ben-Eliezer_0003.png... Correct\n",
      "  99  Binyamin Ben-Eliezer: 0.029\n",
      "Accuracy: 0.890\n"
     ]
    }
   ],
   "source": [
    "classifier(mode = 'CLASSIFY', \n",
    "           data_dir = '../data/newdir_train2_test1/test', \n",
    "           classifier_filename = '../data/newdir_train2_test1/classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
